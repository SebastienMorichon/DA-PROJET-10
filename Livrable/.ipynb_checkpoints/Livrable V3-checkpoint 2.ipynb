{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5308e048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2edc085",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run My_function.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e6f2819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librairies utilisées :\n",
      "Pandas : 1.4.4\n",
      "Numpy : 1.21.5\n",
      "Matplotlib : 3.5.2\n",
      "Seaborn : 0.11.2\n",
      "Spicy : 1.9.1\n",
      "Statmodels : 0.13.2\n",
      "Sklearn : 1.0.2\n"
     ]
    }
   ],
   "source": [
    "print (\"Librairies utilisées :\")\n",
    "print (\"Pandas :\", pd.__version__)\n",
    "print (\"Numpy :\", np.__version__)\n",
    "print (\"Matplotlib :\", matplotlib.__version__)\n",
    "print (\"Seaborn :\", sns.__version__)\n",
    "print (\"Spicy :\", scipy.__version__)\n",
    "print (\"Statmodels :\", statsmodels.__version__)\n",
    "print (\"Sklearn :\", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429c9e85",
   "metadata": {},
   "source": [
    "<div class=\"oc-richContent root-0-2-1\" data-videotitle=\"video\" data-current-user-id=\"328418\" data-project-id=\"863\" data-codio-button-label=\"Accéder au code\"><p>&nbsp;</p>\n",
    "<p><img src=\"https://user.oc-static.com/upload/2023/03/15/16788718737642_Banner-Sce%CC%81nario.png\" alt=\"Bannière scénario\"></p>\n",
    "\n",
    "<p>Vous êtes consultant Data Analyst dans une entreprise spécialisée dans la data. Votre entreprise a décroché une prestation en régie au sein de l’Organisation nationale de lutte contre le faux-monnayage (ONCFM).</p>\n",
    "<p>&nbsp;</p>\n",
    "<figure><a href=\"https://user.oc-static.com/upload/2020/11/25/16063163322759_Screen%20Shot%202020-11-05%20at%2011.15.15.png\" class=\"oc-imageLink oc-imageLink--disabled\"><img src=\"https://user.oc-static.com/upload/2020/11/25/16063163322759_Screen%20Shot%202020-11-05%20at%2011.15.15.png\" alt=\"\"></a></figure>\n",
    "<p>&nbsp;</p>\n",
    "<p>Cette institution a pour objectif de mettre en place des méthodes d’identification des contrefaçons des billets en euros. Ils font donc appel à vous, spécialiste de la data, pour mettre en place une modélisation qui serait capable d’identifier automatiquement les vrais des faux billets. Et ce à partir simplement de certaines dimensions du billet et des éléments qui le composent.</p>\n",
    "<p>Voici <a href=\"https://s3-eu-west-1.amazonaws.com/static.oc-static.com/prod/courses/files/parcours-data-analyst/DAN-P10-cdc-detection-faux-billets.pdf\">le cahier des charges de l’ONCFM</a>, ainsi que&nbsp;<a href=\"https://s3-eu-west-1.amazonaws.com/static.oc-static.com/prod/courses/files/parcours-data-analyst/billets.csv\">le jeu de données</a>.</p>\n",
    "<p>Le client souhaite que vous travailliez directement depuis ses locaux sous la responsabilité de Marie, responsable du projet d’analyse de données à l’ONCFM. Elle vous laissera une grande autonomie pendant votre mission, et vous demande simplement que vous lui présentiez vos résultats une fois la mission terminée. Elle souhaite voir quels sont les traitements et analyses que vous avez réalisés en amont, les différentes pistes explorées pour la construction de l’algorithme, ainsi que le modèle final retenu.</p>\n",
    "<p>Après avoir lu en détail le cahier des charges, vous vous préparez à vous rendre à l’ONCFM pour prendre vos nouvelles fonctions. Vous notez tout de même un post-it qui se trouve sur le coin de votre bureau, laissé par un de vos collègues :</p>\n",
    "<figure><a href=\"https://user.oc-static.com/upload/2020/11/25/16063165227448_De%CC%81tectez%20des%20faux%20billets%20-%20post%20it.png\" class=\"oc-imageLink oc-imageLink--disabled\"><img src=\"https://user.oc-static.com/upload/2020/11/25/16063165227448_De%CC%81tectez%20des%20faux%20billets%20-%20post%20it.png\" alt=\"Lors de ma précédente mission, je me suis retrouvé avec un jeu de données comportant plein de valeurs manquantes, une vraie galère&nbsp;! Mais j’ai eu de très bons résultats en utilisant une régression linéaire pour combler ces dernières. Ça te servira peut-être pour ta prochaine mission, qui sait&nbsp;?\"></a></figure>\n",
    "<p>Vous embarquez le post-it dans vos affaires et vous dirigez donc à présent vers les bureaux de l’ONCFM pour commencer votre mission.</p>\n",
    "\n",
    "<p><img src=\"https://user.oc-static.com/upload/2023/03/15/16788719253125_Banner-Livrables.png\" alt=\"Bannière livrables\"></p>\n",
    "\n",
    "<ul>\n",
    "<li>Votre code en R ou Python contenant :&nbsp;</li>\n",
    "<ul>\n",
    "<li>l’ensemble des traitements et des tests effectués ;</li>\n",
    "<li>l’application finale.</li>\n",
    "</ul>\n",
    "</ul>\n",
    "<aside data-claire-semantic=\"information\">\n",
    "<p>Pour faciliter votre passage devant le jury, déposez sur la plateforme, dans un dossier zip nommé “<strong><em>Titre_du_projet_nom_prénom</em></strong>”, le livrable du projet nommé comme suit : <strong>Nom</strong>_<strong>Prénom</strong>_<strong>n° du livrable</strong>_<strong>nom du livrable</strong>_<strong>date de démarrage du projet</strong>. Cela donnera :&nbsp;</p>\n",
    "<ul>\n",
    "<li><em>Nom_Prénom_1_code_mmaaaa</em></li>\n",
    "</ul>\n",
    "<p>Par exemple, le livrable peut être nommé comme suit <em>: Dupont_Jean_1_code</em>_<em>012023.</em></p>\n",
    "</aside>\n",
    "\n",
    "<p><img src=\"https://user.oc-static.com/upload/2023/03/15/16788719600459_Banner-Soutenance.png\" alt=\"Bannière soutenance\"></p>\n",
    "<p>Durant la présentation orale, votre mentor jouera le rôle de Marie, la responsable du projet à l’ONCFM à qui vous présentez vos résultats :&nbsp;</p>\n",
    "<ul>\n",
    "<li><strong>Présentation des livrables (20 minutes)&nbsp;</strong>\n",
    "<ul>\n",
    "<li>Présentation de l’ensemble de votre cheminement, des traitements et analyses réalisés en amont, des différentes pistes explorées pour la construction de l’algorithme, et du modèle final retenu (15 minutes) ;</li>\n",
    "<li>Test de l’algorithme en direct avec un jeu de données qui vous sera fourni pendant la soutenance, ayant la même forme que le jeu suivant : <a href=\"https://s3-eu-west-1.amazonaws.com/static.oc-static.com/prod/courses/files/parcours-data-analyst/billets_production.csv\">FICHIER billets_production.csv</a>&nbsp;(5&nbsp;minutes).</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li><strong>Discussion (5 minutes)</strong>\n",
    "<ul>\n",
    "<li>Échange de questions/réponses : l’évaluateur pourra revenir sur certains points pour vous questionner sur vos choix.</li>\n",
    "<li>L’évaluateur vous fera un retour sur votre prestation en soutenance.</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li><strong>Debriefing (5 minutes)</strong></li>\n",
    "<ul>\n",
    "<li>À la fin de la soutenance, l'évaluateur arrêtera de jouer le rôle de Marie pour vous permettre de débriefer ensemble.</li>\n",
    "</ul>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49986aa",
   "metadata": {},
   "source": [
    "# Récupération des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a97ed665",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Données/billets.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e297e176",
   "metadata": {},
   "source": [
    "# Exploration des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b81eb28",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd7655c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_genuine</th>\n",
       "      <th>diagonal</th>\n",
       "      <th>height_left</th>\n",
       "      <th>height_right</th>\n",
       "      <th>margin_low</th>\n",
       "      <th>margin_up</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>171.81</td>\n",
       "      <td>104.86</td>\n",
       "      <td>104.95</td>\n",
       "      <td>4.52</td>\n",
       "      <td>2.89</td>\n",
       "      <td>112.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>171.46</td>\n",
       "      <td>103.36</td>\n",
       "      <td>103.66</td>\n",
       "      <td>3.77</td>\n",
       "      <td>2.99</td>\n",
       "      <td>113.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>172.69</td>\n",
       "      <td>104.48</td>\n",
       "      <td>103.50</td>\n",
       "      <td>4.40</td>\n",
       "      <td>2.94</td>\n",
       "      <td>113.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>171.36</td>\n",
       "      <td>103.91</td>\n",
       "      <td>103.94</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.01</td>\n",
       "      <td>113.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>171.73</td>\n",
       "      <td>104.28</td>\n",
       "      <td>103.46</td>\n",
       "      <td>4.04</td>\n",
       "      <td>3.48</td>\n",
       "      <td>112.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_genuine  diagonal  height_left  height_right  margin_low  margin_up  \\\n",
       "0        True    171.81       104.86        104.95        4.52       2.89   \n",
       "1        True    171.46       103.36        103.66        3.77       2.99   \n",
       "2        True    172.69       104.48        103.50        4.40       2.94   \n",
       "3        True    171.36       103.91        103.94        3.62       3.01   \n",
       "4        True    171.73       104.28        103.46        4.04       3.48   \n",
       "\n",
       "   length  \n",
       "0  112.83  \n",
       "1  113.09  \n",
       "2  113.16  \n",
       "3  113.51  \n",
       "4  112.54  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24a2451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On réalise une rapide analyse de nos données. On constate qu'il y a des valeurs manquantes dans la colonnes margin_low\n",
    "my_first_analyse(data, graphique=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7bcd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification du nombre de faux billets\n",
    "print(\"Le nombre de vrai billets est de :\",data.loc[data[\"is_genuine\"]==True][\"is_genuine\"].count())\n",
    "print(\"Le nombre de faux billets est de :\",data.loc[data[\"is_genuine\"]==False][\"is_genuine\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0982435a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Information concernant les vrais billets :\")\n",
    "my_exploration(data.loc[data[\"is_genuine\"]==True])\n",
    "print(\"Information concernant les faux billets :\")\n",
    "my_exploration(data.loc[data[\"is_genuine\"]==False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fb30b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On calcule la différence de diagonale entre les vrais et les faux billets\n",
    "diff_diag = (((data.loc[data[\"is_genuine\"]==True][\"diagonal\"].mean())-(data.loc[data[\"is_genuine\"]==False][\"diagonal\"].mean()))/(data.loc[data[\"is_genuine\"]==True][\"diagonal\"].mean()))*100\n",
    "\n",
    "# On calcule la différence de hauteur entre les vrais et les faux billets\n",
    "diff_h_left = (((data.loc[data[\"is_genuine\"]==True][\"height_left\"].mean())-(data.loc[data[\"is_genuine\"]==False][\"height_left\"].mean()))/(data.loc[data[\"is_genuine\"]==True][\"height_left\"].mean()))*100\n",
    "diff_h_right = (((data.loc[data[\"is_genuine\"]==True][\"height_right\"].mean())-(data.loc[data[\"is_genuine\"]==False][\"height_right\"].mean()))/(data.loc[data[\"is_genuine\"]==True][\"height_right\"].mean()))*100\n",
    "\n",
    "# On calcule la différence de marge entre les vrais et les faux billets\n",
    "diff_m_low = (((data.loc[data[\"is_genuine\"]==True][\"margin_low\"].mean())-(data.loc[data[\"is_genuine\"]==False][\"margin_low\"].mean()))/(data.loc[data[\"is_genuine\"]==True][\"margin_low\"].mean()))*100\n",
    "diff_m_up = (((data.loc[data[\"is_genuine\"]==True][\"margin_up\"].mean())-(data.loc[data[\"is_genuine\"]==False][\"margin_up\"].mean()))/(data.loc[data[\"is_genuine\"]==True][\"margin_up\"].mean()))*100\n",
    "\n",
    "# On calcule la différence de longeur entre les vrais et les faux billets\n",
    "diff_length = (((data.loc[data[\"is_genuine\"]==True][\"length\"].mean())-(data.loc[data[\"is_genuine\"]==False][\"length\"].mean()))/(data.loc[data[\"is_genuine\"]==True][\"length\"].mean()))*100\n",
    "\n",
    "# Affichage des résultats sous forme de Tableau\n",
    "pd.DataFrame(index=[\"Moyenne des écrats en %\"],columns=[\"diagonale\",\"height_left\",\"height_right\",\"margin_low\",\"margin_up\",\"length\"],data=[[diff_diag, diff_h_left, diff_h_right, diff_m_low, diff_m_up, diff_length]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646b3961",
   "metadata": {},
   "source": [
    "En comparant les données ci-dessus, on constate que : \n",
    "- Les vrais billets ont une diagonale légèrement plus importante\n",
    "- Les faux billets ont hauteur et des marges lègèrement plus importante\n",
    "- Les faux billets sont plus petit que les vrais billets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee689b40",
   "metadata": {},
   "source": [
    "## Visualisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fa0463",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data, hue=\"is_genuine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7bc06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_boxplots(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498b62b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_corr_heatmap(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ff9e4b",
   "metadata": {},
   "source": [
    "# Nettoyage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31529a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commençons par changer le bool par du binaire pour la colonne is_genuine\n",
    "data[\"is_genuine\"].replace([True, False], [1,0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37f7518",
   "metadata": {},
   "source": [
    "On va maintenant s'occuper des valeurs manquantes. En observant le pairplot précédent, on constate qu'il semble exister une relation entre la longeur et le margin_low. Plusieurs méthodes s'offrent à nous : \n",
    "- Supprimer ces individus (car ne représente (que) 2,47% des valeurs totales)\n",
    "- Appliquer la moyenne \n",
    "- Appliquier la médianne\n",
    "- Utiliser une methode me ML pour reconstituer ces données (ici, régression linéaire)\n",
    "\n",
    "Pour ce cas pratique, nous allons opter pour la dernière méthode. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4de293",
   "metadata": {},
   "source": [
    "## Vérification des valeurs abérantess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c312b4",
   "metadata": {},
   "source": [
    "Nous allons vérifier les données abérantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7f22a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_outliers_zscore(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95ff96c",
   "metadata": {},
   "source": [
    "Les données aberrantes ont une influence fortes sur les différentes modele ML que nous allons mettre en place. De ce fait, nous pourrions rétiere ces valeurs. \n",
    "Cependant, il est interessant de laisser les vrais billets dans le DataSet afin de prendre en compte ces dimentions dans la détection de faux billets. Nous allons simplement retirer les faux billets des outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2472b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On affecte les outliers à une variable\n",
    "outliers = my_outliers_zscore(data)\n",
    "# On selectionne les vrais billets\n",
    "outliers = outliers.loc[outliers[\"is_genuine\"]==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcf6ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On réalise une petite analyse des données outliers\n",
    "my_first_analyse(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dab8695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On créé une nouvelle table sans les outliers\n",
    "data = data.drop(outliers.index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759d33ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158c8691",
   "metadata": {},
   "source": [
    "## Compléter les valeurs manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87656d81",
   "metadata": {},
   "source": [
    "### Régression Linéaire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0872c8a4",
   "metadata": {},
   "source": [
    "On a constaté durant l'exploration des données que nous avions des valeurs manquantes dans la colonne \"Margin_low\".\n",
    "Nous souhaitons pouvoir \"prédire\" ces données à l'aide d'un model de Machine Learning. Dans notre cas, nous allons tester le model de <b>Régression Linéaire</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f36d96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe LinearRegression()\n",
    "# Avec Sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Avec StatModel\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c063eb1",
   "metadata": {},
   "source": [
    "On va commencer par séparer les individus qui ont une valeur manquante dans \"Margin_low\". Cela correspond à 37 individus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bec260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On créé un Dataset avec les individus qui ont un marhin_low = NaN\n",
    "data_vide = data.loc[data[\"margin_low\"].isna()]\n",
    "\n",
    "# On créé un Dataset sans les valeurs manquantes\n",
    "data_non_vide = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc46cb8",
   "metadata": {},
   "source": [
    "#### Avec StatModels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac918b06",
   "metadata": {},
   "source": [
    "###### Backward Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaac80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On utilise la fonction my_backward_selected afin de trouvers les varibles descriptives les plus pertinentes\n",
    "columns = ['margin_low','diagonal','is_genuine','height_left','height_right','margin_up','length']\n",
    "reg_backward = my_backward_selected(data_non_vide[columns], 'margin_low')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a44a75",
   "metadata": {},
   "source": [
    "Les variables descriptives interessantes sont : \n",
    "- is_genuine\n",
    "- margin_up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5677795",
   "metadata": {},
   "source": [
    "Une fois les variables descriptives selectionnées. Nous pouvons définir X et y et réaliser notre régression linéaire : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0078c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On définit nos valeurs X et y\n",
    "X = data_non_vide.drop(['margin_low','diagonal','height_left','height_right','length'], axis=1)\n",
    "X = sm.add_constant(X, has_constant='add')\n",
    "y = data_non_vide[\"margin_low\"].values.reshape(len(data_non_vide),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a4c23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71fa6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On split notre jeu de donnée\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062b07f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_01 = sm.OLS(y_train, X_train)\n",
    "resultat = model_01.fit()\n",
    "\n",
    "y_pred = resultat.predict(X_train)\n",
    "\n",
    "print(resultat.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48076bf5",
   "metadata": {},
   "source": [
    "### Vérification des hypothèses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6b7e04",
   "metadata": {},
   "source": [
    "Avant de valider l'utilisation de la régression linéaire, nous devons vérifier plusieurs hypothèses afin de s'assurer que nous pouvons appliquer cette régression. Voici les hypothèses à vérifier : \n",
    "- <b>Linéarité</b> : L'hypothèse de base de la régression linéaire est que la relation entre les variables indépendantes et dépendantes est linéaire.\n",
    "- <b>Indépendance</b> : Les observations doivent être indépendantes les unes des autres. En d'autres termes, il ne devrait pas y avoir de corrélation ou de dépendance entre les observations.\n",
    "- <b>Homoscédasticité</b> : L'homoscédasticité signifie que la variance des erreurs résiduelles est constante à tous les niveaux de la variable prédite.\n",
    "- <b>Normalité</b> : Les erreurs résiduelles doivent être distribuées normalement. Cela signifie que les résidus doivent suivre une distribution normale avec une moyenne de zéro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ba60d6",
   "metadata": {},
   "source": [
    "#### Linéarité"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565d619f",
   "metadata": {},
   "source": [
    "<b>Graphique : Résidus en fonction des valeurs ajustées</b>\n",
    "\n",
    "On trace les résidus en fonction des valeurs ajustées (les Ŷ). Le tracé rouge doit être approximativement horizontal s’il y a bien une relation linéaire. Ce tracé est un ajustement du nuage de points qui utilise une méthode de régression non-linéaire appelée régression locale ou LOESS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445eae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "\n",
    "# Calcul des résidus\n",
    "residuals = resultat.resid\n",
    "\n",
    "# Calcul du LOESS\n",
    "smoothed = lowess(residuals, y_pred)\n",
    "\n",
    "# Tracé des résidus en fonction des valeurs ajustées\n",
    "plt.scatter(y_pred, residuals, color='b', alpha=0.6, label='Résidus')\n",
    "plt.plot(smoothed[:, 0], smoothed[:, 1], color='r', label='LOESS')\n",
    "plt.axhline(y=0, color='k', linestyle='--')\n",
    "plt.xlabel('Valeurs ajustées')\n",
    "plt.ylabel('Résidus')\n",
    "plt.legend()\n",
    "plt.title('Résidus en fonction des valeurs ajustées')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abf874e",
   "metadata": {},
   "source": [
    "Le tracé rouge semble relativement horizontal. Nous allons pouvoir vérifier cela par le <b>Test de Rainbow</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2f0cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import linear_rainbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32611fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul du test de linéarité de Rainbow\n",
    "rainbow_statistic, rainbow_p_value = linear_rainbow(resultat)\n",
    "\n",
    "print(\"Rainbow Test Statistic:\", rainbow_statistic)\n",
    "print(\"Rainbow Test p-value:\", rainbow_p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b46e93",
   "metadata": {},
   "source": [
    "Le Rainbow test nous indique un p-value inférieur à 0.05. En d'autres termes, nous pouvons rejeter l'hypothèse nulle de linéarité. Le test a détecté suffisamment d'évidence pour conclure que notre modèle de régression linéaire représente correctement une relation non-linéaire entre les variables indépendantes et la variable dépendante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96517263",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613d67fc",
   "metadata": {},
   "source": [
    "#### Indépendance des résidus "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db2a579",
   "metadata": {},
   "source": [
    "<b>Test de Ljung-Box</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8814b2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import acorr_ljungbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d848db",
   "metadata": {},
   "outputs": [],
   "source": [
    "compteur = 0\n",
    "\n",
    "# Test de Ljung-Box\n",
    "lb_test = acorr_ljungbox(residuals, lags=30)\n",
    "\n",
    "# Récupération des statistiques de test (Q) et des p-values\n",
    "lb_statistic = lb_test[\"lb_stat\"]\n",
    "lb_pvalue = lb_test[\"lb_pvalue\"]\n",
    "\n",
    "# Affichage des résultats\n",
    "for lag, statistic, pvalue in zip(range(1, len(lb_statistic) + 1), lb_statistic, lb_pvalue):\n",
    "    if pvalue<0.05 : \n",
    "        print(f\"Lag {lag}: Statistique du test de Ljung-Box = {statistic}, p-value = {pvalue}\")\n",
    "        compteur = compteur +1\n",
    "if compteur ==0:\n",
    "    print(\"Test de Ljung-Box passé avec succès\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b5a443",
   "metadata": {},
   "source": [
    "Dans notre cas, les p-values pour tous les lags sont supérieures à 0,05, ce qui indique qu'il n'y a pas de corrélation significative entre les résidus aux différents décalages. Cela suggère que les résidus sont indépendants et qu'il n'y a pas d'autocorrélation systématique dans vos données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2224314b",
   "metadata": {},
   "source": [
    "<b>Test de Durbin-Watson</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff132c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dw_test = sm.stats.stattools.durbin_watson(residuals)\n",
    "\n",
    "# Affichage du résultat\n",
    "print(\"Statistique de Durbin-Watson :\", dw_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a20fa79",
   "metadata": {},
   "source": [
    "- <span style=\"color:green\">Une valeur proche de 2 indique une absence ou une autocorrélation faible des résidus.</span>\n",
    "- Une valeur inférieure à 2 suggère une autocorrélation positive (corrélation positive entre les résidus).\n",
    "- Une valeur supérieure à 2 suggère une autocorrélation négative (corrélation négative entre les résidus)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8cb680",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b79405",
   "metadata": {},
   "source": [
    "#### Homogénéité des résidus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8c6c47",
   "metadata": {},
   "source": [
    "Pour tester l'Homogénéité des résidus, nous allons réaliser les tests de <b>Breusch-Pagan</b> et de <b>White</b> : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1f69dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.compat import lzip\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan, het_white\n",
    "\n",
    "# Obtention des variables explicatives du modèle (exog)\n",
    "exog = resultat.model.exog\n",
    "\n",
    "# Test de Breusch-Pagan\n",
    "bp_test = het_breuschpagan(residuals, exog_het=exog)\n",
    "\n",
    "# Test de White\n",
    "white_test = het_white(residuals, exog=exog)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Test de Breusch-Pagan:\")\n",
    "labels = ['LM Statistic', 'LM p-value', 'F Statistic', 'F p-value']\n",
    "print(lzip(labels, bp_test))\n",
    "\n",
    "print(\"\\nTest de White:\")\n",
    "labels = ['LM Statistic', 'LM p-value', 'F Statistic', 'F p-value']\n",
    "print(lzip(labels, white_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85370e5e",
   "metadata": {},
   "source": [
    "<b>Test de Breusch-Pagan:</b>\n",
    "\n",
    "Le fait que la p-value soit faible (inférieure à 0,05) indique que l'hypothèse d'homogénéité des résidus est violée. Cela suggère la présence d'une variance non constante des résidus, ce qui peut affecter la précision et la validité des résultats de votre modèle.\n",
    "\n",
    "<b>Test de White:</b>\n",
    "\n",
    "Les résultats du test de White confirment également la présence d'hétéroscédasticité, avec des p-values faibles.\n",
    "\n",
    "En conclusion, ces résultats suggèrent que <b><span style=\"color:red\">l'hypothèse d'homogénéité des résidus n'est pas vérifiée</span></b> dans votre modèle de régression linéaire. Il peut être nécessaire de prendre des mesures pour remédier à l'hétéroscédasticité, par exemple en utilisant des méthodes de pondération ou en transformant les variables pour obtenir une variance plus constante des résidus.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5b5ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=residuals.index, y=residuals, alpha=0.6)\n",
    "plt.plot(np.repeat(0, len(data.index)), color=\"black\", linestyle='--')\n",
    "plt.title(\"Homoscédasticité\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475410f6",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a3ae9e",
   "metadata": {},
   "source": [
    "#### Hypothèse de la normalité des résidus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fbd9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.qqplot(residuals, line='s', label=\"Résidus\")\n",
    "plt.title(\"Hypothèse de la normalité des résidus  : Q-Q plot\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7c25a7",
   "metadata": {},
   "source": [
    "<b>Test de Shapiro-Wilk</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44927c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "statistic, p_value = shapiro(residuals)\n",
    "\n",
    "if p_value > 0.05:\n",
    "    print(\"Les résidus semblent suivre une distribution normale (hypothèse non rejetée).\")\n",
    "    print(\"P-value :\",p_value)\n",
    "else:\n",
    "    print(\"Les résidus ne suivent pas une distribution normale (hypothèse rejetée).\")\n",
    "    print(\"P-value :\",p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97aaef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(residuals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cda6a0",
   "metadata": {},
   "source": [
    "Conclusion des vérification des hypothèses de la régression linéaire : \n",
    "- Linéarité : <b><span style=\"color:red\">NON VERIFIÉ</span></b>\n",
    "- Indépendance des résidus : <b><span style=\"color:green\">VERIFIÉ </span></b>\n",
    "- Homogénéité des résidus : <b><span style=\"color:red\">NON VERIFIÉ</span></b>\n",
    "- Normalité des résidus : <b><span style=\"color:red\">NON VERIFIÉ</span></b>\n",
    "\n",
    "En résumé, bien que la linéarité et la normalité des résidus soient vérifiées, les violations de l'indépendance des résidus et de l'homogénéité des résidus peuvent remettre en question l'utilisation directe de la régression linéaire."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c69110a",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824067e4",
   "metadata": {},
   "source": [
    "### Mise en application de la régression linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c05d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On définit nos valeurs X et y\n",
    "X = data_vide.drop([\"margin_low\",\"height_right\",\"length\",\"diagonal\",\"height_left\"], axis=1)\n",
    "X = sm.add_constant(X)\n",
    "y = data_vide[\"margin_low\"].values.reshape(len(data_vide),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7093d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On réalise la prédiction à l'aide du model créé avec StatModel\n",
    "prediction = resultat.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b45e64",
   "metadata": {},
   "source": [
    "Maintenant que nous avons nos données dans un tableau, nous allons pouvoir les assigner à notre table data_vide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a71018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On assigne les données prédites à notre dataframe avec les valeurs vides\n",
    "new_data = data_vide.assign(margin_low=prediction)\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a84290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ajoute les nouvelles données aux données de base\n",
    "data = data_non_vide.append(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172d13d1",
   "metadata": {},
   "source": [
    "Afin de vérifier la cohérence des résultats obtenus. Nous allons vérifier quelques informations sur ces données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0134f0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Avec la prédiction du model de Régression Linéaire\")\n",
    "display(data[[\"margin_low\"]].describe())\n",
    "print(\"Sans la prédiction du model de Régression Linéaire\")\n",
    "display(data_non_vide[[\"margin_low\"]].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e52e8c",
   "metadata": {},
   "source": [
    "Les données semblent cohérentes. Il n'y a pas de différences majeur dans les données depuis l'ajout des nouvelles variables calculées à l'aide de la régression linéaire. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960c93df",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_first_analyse(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e78a51",
   "metadata": {},
   "source": [
    "# Prédiction des billets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7731d1",
   "metadata": {},
   "source": [
    "Pour la mise en palce d'un modele capable de prédire au mieux si un billet et vrai ou faux, nous allons tester plusieurs méthodes : \n",
    "\n",
    "- LogisticRegression\n",
    "- K-Means\n",
    "\n",
    "<b>Bonus :</b> \n",
    "- KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4570d964",
   "metadata": {},
   "source": [
    "## Régression Logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c24663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe la librairie nous permettant de faire une Régression Logistique\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# On importe les librairies nécessaire pour réaliser une matrice de confusion\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6226ab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On affecte à nos X et y les données nécessaires\n",
    "X = data.drop(\"is_genuine\", axis=1)\n",
    "y = data[\"is_genuine\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe3fe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On définit notre Train Set et notre Test Set\n",
    "X_train ,X_test, y_train, y_test = train_test_split(X,y, train_size=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137bae70",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_first_analyse(data).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98afca47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On définit notre model\n",
    "model_03 = LogisticRegression()\n",
    "\n",
    "# On entraine notre model\n",
    "model_03 = model_03.fit(X_train, y_train)\n",
    "\n",
    "# On enregistre les prédictions dans une variable y_pred\n",
    "y_pred = model_03.predict(X_test)\n",
    "\n",
    "# On vérifie le score de notre model sur les données Test\n",
    "score = model_03.score(X_test, y_test)\n",
    "score = round(score*100,4)\n",
    "print(\"Le score de notre model sur les données Test est de :\", score,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cbf783",
   "metadata": {},
   "source": [
    "### Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff21a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d78395",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b053b526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c692464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kmeans = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66358ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On affecte à nos X et y les données nécessaires\n",
    "X = data_kmeans.drop(\"is_genuine\", axis=1)\n",
    "y = data_kmeans[\"is_genuine\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c9ec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1204ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cluster = my_kmeans_coude(X_train, graphique=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fab1c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_04 =KMeans(n_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acfb2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_04.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447c2e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère les labels calculé à l'aide de notre model\n",
    "labels = model_04.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd6dffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30ccfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On créé une colonne dans notre table en ajoutant les labels calculé par le model\n",
    "X_train[\"cluster\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8267a1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4420c640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On calcule le score et on inverse les cluster si besoin. \n",
    "score = f1_score(y_train, X_train[\"cluster\"])\n",
    "if score <0.5:\n",
    "    X_train[\"cluster\"].replace([0,1], [1,0], inplace=True)\n",
    "    score = f1_score(y_train, X_train[\"cluster\"])\n",
    "    print(\"Le score est de:\",round(score*100,4),\"%\")\n",
    "else : \n",
    "    print(\"Le score est de:\",round(score*100,4),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c69a9cc",
   "metadata": {},
   "source": [
    "Sur le test set : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4703fb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model_04.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4767d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On créé une colonne dans notre table en ajoutant les labels calculé par le model\n",
    "X_test[\"cluster\"] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40d3da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5e5ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On calcule le score et on inverse les cluster si besoin. \n",
    "score = f1_score(y_test, X_test[\"cluster\"])\n",
    "if score <0.5:\n",
    "    X_test[\"cluster\"].replace([0,1], [1,0], inplace=True)\n",
    "    score = f1_score(y_test, X_test[\"cluster\"])\n",
    "    print(\"Le score est de:\",round(score*100,4),\"%\")\n",
    "else : \n",
    "    print(\"Le score est de:\",round(score*100,4),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5114576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(model_04, 'modele_kmeans.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e3ea18",
   "metadata": {},
   "source": [
    "### Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d042299",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = confusion_matrix(y_train, X_train.cluster)\n",
    "cm = ConfusionMatrixDisplay(cf)\n",
    "cm.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb8ea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Calcul du Rand Score\n",
    "rand_score = adjusted_rand_score(y_test, X_test[\"cluster\"])\n",
    "# Calcul du F1 score\n",
    "f1 = f1_score(y_test, X_test[\"cluster\"])\n",
    "\n",
    "print(\"Adjusted_rand_score :\",round(rand_score*100,4),\"%\")\n",
    "print(\"Le F1 score est de:\",round(f1*100,4),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7573040",
   "metadata": {},
   "source": [
    "## KNeighborsClassifier (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28d285f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe KNeighborsClassifier de SKlearn\n",
    "from sklearn.neighbors import KNeighborsClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c63954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On affecte à nos X et y les données nécessaires\n",
    "X = data.drop(\"is_genuine\", axis=1)\n",
    "y = data[\"is_genuine\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8078cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On créé nos DataSet de train et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b8c151",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2c2067",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import  GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafbe305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On définit les paramètres à tester\n",
    "param = {\n",
    "    \"n_neighbors\" : np.arange(1,50),\n",
    "    \"weights\" : [\"uniform\",\"distance\"],\n",
    "    \"algorithm\" : ['auto','ball_tree', 'kd_tree', 'brute'] \n",
    "}\n",
    "\n",
    "# On ajoute notre GridSearchCV a une variable\n",
    "grid = GridSearchCV(KNeighborsClassifier(),param,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d875edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On entraine notre GridSerachCV avec nos données d'entrainement\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e18c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On regarde quelle a été le meilleur score obtenu en croisant les différents paramètres\n",
    "grid.best_score_\n",
    "print(\"Le meilleur score obtenu avec les données d'entrainement est de :\", round(grid.best_score_*100,4),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372d7eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On fait apparaitre les meilleurs paramètres qui ont donnés le score au dessus\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e846d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On enregistre les paramètres dans une variable model. Cela nous permettra de réutiliser ses paramètres pour tester nos données Test\n",
    "model_02 = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e245a289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On vérifie le score de notre model optimisé avec les données Test\n",
    "score = model_02.score(X_test, y_test)\n",
    "print(\"Le score de notre model sur les données Test est de :\", round(score*100,4),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cc7cd8",
   "metadata": {},
   "source": [
    "### Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697f21a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On réalise notre matrice de confusion\n",
    "y_pred = model_02.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3664c7",
   "metadata": {},
   "source": [
    "### Validation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32000833",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "\n",
    "# Définir les valeurs de l'hyperparamètre à tester\n",
    "param_range = np.arange(1, 50)\n",
    "\n",
    "# Calculer la validation croisée pour différentes valeurs de l'hyperparamètre\n",
    "train_scores, test_scores = validation_curve(\n",
    "    KNeighborsClassifier(),\n",
    "    X_train, y_train, param_name=\"n_neighbors\",\n",
    "    param_range=param_range, cv=5, scoring=\"accuracy\"\n",
    ")\n",
    "\n",
    "# Calculer la moyenne et l'écart type des scores d'entraînement et de test\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Tracer la courbe de validation\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Validation Curve avec un KNeighborsClassifier\")\n",
    "plt.xlabel(\"Nombre de Voisins (k)\")\n",
    "plt.ylabel(\"Précision\")\n",
    "plt.ylim(0.97, 1.00)\n",
    "plt.plot(param_range, train_mean, label=\"Précision sur le TrainSet\", color=\"blue\")\n",
    "plt.fill_between(param_range, train_mean - train_std, train_mean + train_std, alpha=0.2, color=\"blue\")\n",
    "plt.plot(param_range, test_mean, label=\"Précision sur le TestSet\", color=\"red\")\n",
    "plt.fill_between(param_range, test_mean - test_std, test_mean + test_std, alpha=0.2, color=\"red\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9d418e",
   "metadata": {},
   "source": [
    "Les résultats indiquent que la précision moyenne sur l'ensemble d'entraînement diminue légèrement à mesure que la valeur de l'hyperparamètre (k) augmente. Cela peut être dû à une plus grande complexité du modèle avec un nombre plus élevé de voisins, ce qui peut conduire à un surajustement (overfitting) aux données d'entraînement.\n",
    "\n",
    "D'autre part, la précision moyenne sur l'ensemble de test atteint un plateau à partir d'une certaine valeur de l'hyperparamètre (k) (environ 12). Cela peut indiquer que le modèle atteint sa capacité maximale de généralisation et n'améliore pas sa performance sur l'ensemble de test avec des valeurs plus élevées de k.\n",
    "\n",
    "En résumé, ces résultats suggèrent qu'une valeur de k entre 1 et 12 serait appropriée pour le modèle KNeighborsClassifier utilisé avec notre ensemble de données. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0ff7ef",
   "metadata": {},
   "source": [
    "### Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d235a810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# Définir les tailles des ensembles d'entraînement à tester\n",
    "train_sizes = np.linspace(0.1, 1.0, 10)\n",
    "\n",
    "# Calculer les courbes d'apprentissage pour différentes tailles d'ensemble d'entraînement\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    KNeighborsClassifier(n_neighbors=5), X_train, y_train,\n",
    "    train_sizes=train_sizes, cv=5, scoring='accuracy'\n",
    ")\n",
    "\n",
    "# Calculer la moyenne et l'écart type des scores d'entraînement et de test\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Tracer la courbe d'apprentissage\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Learning Curve avec un KNeighborsClassifier\")\n",
    "plt.xlabel(\"Nombre d'individus\")\n",
    "plt.ylabel(\"Précision\")\n",
    "plt.ylim(0.97, 1.00)\n",
    "plt.plot(train_sizes, train_mean, 'o-', color=\"blue\", label=\"Précision sur le TrainSet\")\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.2, color=\"blue\")\n",
    "plt.plot(train_sizes, test_mean, 'o-', color=\"red\", label=\"Précision sur le TestSet\")\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.2, color=\"red\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c05f3e",
   "metadata": {},
   "source": [
    "Les résultats indiquent que la précision moyenne sur l'ensemble d'entraînement augmente à mesure que la taille de l'ensemble d'entraînement augmente. Cela est généralement attendu, car un modèle a plus de données pour apprendre et s'ajuster.\n",
    "\n",
    "Cependant, la précision moyenne sur l'ensemble de test atteint un plateau à partir d'une certaine taille d'ensemble d'entraînement (environ 200 individus). Cela peut indiquer que le modèle atteint sa capacité maximale d'apprentissage et n'améliore pas sa performance sur l'ensemble de test avec plus de données.\n",
    "\n",
    "En résumé, ces résultats suggèrent que l'ajout de plus de données au modèle d'apprentissage n'améliore pas significativement sa performance sur l'ensemble de test, et il est possible que d'autres facteurs, tels que la sélection des fonctionnalités ou les hyperparamètres du modèle, doivent être pris en compte pour obtenir de meilleures performances."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Sommaire ",
   "toc_cell": false,
   "toc_position": {
    "height": "820px",
    "left": "1536px",
    "top": "110px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
